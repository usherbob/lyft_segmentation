{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这部分是模型训练与验证的主要代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACTS_FOLDER = \"./artifacts\"\n",
    "!rm -rf images\n",
    "!rm -rf maps\n",
    "!rm -rf lidar\n",
    "!ln -s /home/bob/data/lyft_data/train_images images\n",
    "!ln -s /home/bob/data/lyft_data/train_maps maps\n",
    "!ln -s /home/bob/data/lyft_data/train_lidar lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import glob\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Disable multiprocesing for numpy/opencv. We already multiprocess ourselves, this would mean every subprocess produces\n",
    "# even more threads which would lead to a lot of context switching, slowing things down a lot.\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import scipy.special\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "from lyft_dataset_sdk.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformation_matrix_to_voxel_space(shape, voxel_size, offset):\n",
    "    \"\"\"\n",
    "    Constructs a transformation matrix given an output voxel shape such that (0,0,0) ends up in the center.\n",
    "    Voxel_size defines how large every voxel is in world coordinate, \n",
    "    (1,1,1) would be the same as Minecraft voxels.\n",
    "    An offset per axis in world coordinates (metric) can be provided, \n",
    "    this is useful for Z (up-down) in lidar points.\n",
    "    No rotation, only a scale and translation.\n",
    "    \"\"\"\n",
    "    \n",
    "    shape, voxel_size, offset = np.array(shape), np.array(voxel_size), np.array(offset)\n",
    "    tm = np.eye(4, dtype=np.float32) #(4,4)\n",
    "    translation = shape/2 + offset/voxel_size #(3,)\n",
    "    tm = tm * np.array(np.hstack((1/voxel_size, [1]))) # (4,4)\n",
    "    tm[:3, 3] = np.transpose(translation)\n",
    "    return tm\n",
    "\n",
    "def transform_points(points, transf_matrix):\n",
    "    \"\"\"\n",
    "    Transform (3,N) or (4,N) points using transformation matrix.\n",
    "    \"\"\"\n",
    "    if points.shape[0] not in [3,4]:\n",
    "        raise Exception(\"Points input should be (3,N) or (4,N) shape, received {}\".format(points.shape))\n",
    "    return transf_matrix.dot(np.vstack((points[:3, :], np.ones(points.shape[1]))))[:3, :]\n",
    "\n",
    "def car_to_voxel_coords(points, shape, voxel_size, z_offset=0):\n",
    "    if len(shape) != 3:\n",
    "        raise Exception(\"Voxel volume shape should be 3 dimensions (x,y,z)\")\n",
    "        \n",
    "    if len(points.shape) != 2 or points.shape[0] not in [3, 4]:\n",
    "        raise Exception(\"Input points should be (3,N) or (4,N) in shape, found {}\".format(points.shape))\n",
    "\n",
    "    tm = create_transformation_matrix_to_voxel_space(shape, voxel_size, (0, 0, z_offset))\n",
    "    p = transform_points(points, tm) #(3, N)\n",
    "    return p\n",
    "\n",
    "def create_voxel_pointcloud(points, shape, voxel_size=(0.5,0.5,1), z_offset=0):\n",
    "\n",
    "    points_voxel_coords = car_to_voxel_coords(points.copy(), shape, voxel_size, z_offset) #(3,N)\n",
    "    points_voxel_coords = points_voxel_coords[:3].transpose(1,0) #(N, 3)\n",
    "    points_voxel_coords = np.int0(points_voxel_coords)\n",
    "    bev = np.zeros(shape, dtype=np.float32)\n",
    "    bev_shape = np.array(shape)\n",
    "    within_bounds = (np.all(points_voxel_coords >= 0, axis=1) * np.all(\n",
    "        points_voxel_coords < bev_shape, axis=1))\n",
    "    points_voxel_coords = points_voxel_coords[within_bounds]\n",
    "    coord, count = np.unique(points_voxel_coords, axis=0, return_counts=True)\n",
    "    # Note X and Y are flipped:\n",
    "    bev[coord[:,1], coord[:,0], coord[:,2]] = count\n",
    "    \n",
    "    return bev\n",
    "\n",
    "def normalize_voxel_intensities(bev, max_intensity=16):\n",
    "    return (bev/max_intensity).clip(0,1)\n",
    "\n",
    "def move_boxes_to_car_space(boxes, ego_pose):\n",
    "    \"\"\"\n",
    "    Move boxes from world space to car space.\n",
    "    Note: mutates input boxes.\n",
    "    \"\"\"\n",
    "    translation = -np.array(ego_pose['translation'])\n",
    "    rotation = Quaternion(ego_pose['rotation']).inverse\n",
    "    for box in boxes:\n",
    "        # Bring box to car space\n",
    "        box.translate(translation)\n",
    "        box.rotate(rotation)\n",
    "        \n",
    "def scale_boxes(boxes, factor):\n",
    "    \"\"\"\n",
    "    Note: mutates input boxes\n",
    "    \"\"\"\n",
    "    for box in boxes:\n",
    "        box.wlh = box.wlh * factor\n",
    "\n",
    "def draw_boxes(im, voxel_size, boxes, classes, z_offset=0.0):\n",
    "    for box in boxes:\n",
    "        # We only care about the bottom corners\n",
    "        corners = box.bottom_corners()\n",
    "        corners_voxel = car_to_voxel_coords(corners, im.shape, voxel_size, z_offset).transpose(1,0)\n",
    "        corners_voxel = corners_voxel[:,:2] # Drop z coord\n",
    "        class_color = classes.index(box.name) + 1\n",
    "        if class_color == 0:\n",
    "            raise Exception(\"Unknown class: {}\".format(box.name))\n",
    "        cv2.drawContours(im, np.int0([corners_voxel]), 0, (class_color, class_color, class_color), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BEVImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_filepaths, target_filepaths, map_filepaths=None):\n",
    "        self.input_filepaths = input_filepaths\n",
    "        self.target_filepaths = target_filepaths\n",
    "        self.map_filepaths = map_filepaths\n",
    "        \n",
    "        if map_filepaths is not None:\n",
    "            assert len(input_filepaths) == len(map_filepaths)        \n",
    "        assert len(input_filepaths) == len(target_filepaths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_filepath = self.input_filepaths[idx]\n",
    "        target_filepath = self.target_filepaths[idx]        \n",
    "        sample_token = input_filepath.split(\"/\")[-1].replace(\"_input.png\",\"\")        \n",
    "        im = cv2.imread(input_filepath, cv2.IMREAD_UNCHANGED)        \n",
    "        if self.map_filepaths:\n",
    "            map_filepath = self.map_filepaths[idx]\n",
    "            map_im = cv2.imread(map_filepath, cv2.IMREAD_UNCHANGED)\n",
    "            im = np.concatenate((im, map_im), axis=2)        \n",
    "        target = cv2.imread(target_filepath, cv2.IMREAD_UNCHANGED)        \n",
    "        im = im.astype(np.float32)/255\n",
    "        target = target.astype(np.int64)        \n",
    "        im = torch.from_numpy(im.transpose(2,0,1))\n",
    "        target = torch.from_numpy(target)      \n",
    "        return im, target, sample_token\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        n_classes=2,\n",
    "        depth=5,\n",
    "        wf=6,\n",
    "        padding=False,\n",
    "        batch_norm=False,\n",
    "        up_mode='upconv',\n",
    "    ):\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels, 2 ** (wf + i), padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        \n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(\n",
    "                UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1) # dropout is absent\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i == len(self.down_path) - 1:\n",
    "                x = self.dropout(x)\n",
    "                continue\n",
    "            elif i == len(self.down_path) - 2:\n",
    "                x = self.dropout(x)\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "            else:\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        return self.last(x)\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1),\n",
    "            )\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"car\", \"motorcycle\", \"bus\", \"bicycle\", \"truck\", \"pedestrian\", \n",
    "           \"other_vehicle\", \"animal\", \"emergency_vehicle\"]\n",
    "train_data_folder = os.path.join(ARTIFACTS_FOLDER, \"bev_train_data\")\n",
    "input_filepaths = sorted(glob.glob(os.path.join(train_data_folder, \"*_input.png\")))\n",
    "target_filepaths = sorted(glob.glob(os.path.join(train_data_folder, \"*_target.png\")))\n",
    "#map_filepaths = sorted(glob.glob(os.path.join(train_data_folder, \"*_map.png\")))\n",
    "train_dataset = BEVImageDataset(input_filepaths, target_filepaths)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "\n",
    "validation_data_folder = os.path.join(ARTIFACTS_FOLDER, \"./bev_validation_data\")\n",
    "val_input_filepaths = sorted(glob.glob(os.path.join(validation_data_folder, \"*_input.png\")))\n",
    "val_target_filepaths = sorted(glob.glob(os.path.join(validation_data_folder, \"*_target.png\")))\n",
    "#map_filepaths = sorted(glob.glob(os.path.join(train_data_folder, \"*_map.png\")))\n",
    "val_dataset = BEVImageDataset(val_input_filepaths, val_target_filepaths)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Some hyperparameters we'll need to define for the system\n",
    "voxel_size = (0.3, 0.3, 1.0)\n",
    "z_offset = -2.0\n",
    "bev_shape = (496, 496, 3)\n",
    "# We scale down each box so they are more separated when projected into our coarse voxel space.\n",
    "box_scale = 0.9\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 15\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class_weights = torch.from_numpy(np.array([0.2] + [1.0]*len(classes), dtype=np.float32))\n",
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_model(in_channels=6, num_output_classes=2):\n",
    "    model = UNet(in_channels=in_channels, n_classes=num_output_classes, wf=6, depth=5, padding=True, \n",
    "                 up_mode='upsample')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Val\n",
    "训练模型,并且计算模型在训练集与验证集上的loss,此loss为语义分割loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a67a4a3001a4340b8c121a96d6faac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.012107865\n",
      "./artifacts/unet/unet_epoch_16.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abc451e32f64133bbc27caaf679433b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.009479113\n",
      "Epoch 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5f0ef0b5d14a12b2069ad105495693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.011312767\n",
      "./artifacts/unet/unet_epoch_17.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbfe8d29758404aab6774d5225ec2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.016306445\n",
      "Epoch 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9073c75be084d5a8dea227925f29527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010911989\n",
      "./artifacts/unet/unet_epoch_18.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda83cebb3a145aea2d9828e309d5a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.0093782395\n",
      "Epoch 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a186ea68134ac583a054bad513f90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010692051\n",
      "./artifacts/unet/unet_epoch_19.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3bff1e4d3148639e756192c6f7a0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.010054015\n",
      "Epoch 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d289eedeacc94d9b844ef75e8c493ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0105925575\n",
      "./artifacts/unet/unet_epoch_20.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83533eec7943464c9b333d7b947cde3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.012236119\n",
      "Epoch 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6725736eb24a7a808964bbba8df835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010536369\n",
      "./artifacts/unet/unet_epoch_21.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696741b3b55d4808bb76aa096afcbce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.014131637\n",
      "Epoch 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a207d5ac414d59a84359d578a1cf97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.01051307\n",
      "./artifacts/unet/unet_epoch_22.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4899ba5f865c48c185a7aba55447d6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.009112576\n",
      "Epoch 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258b22a45175416784cc19ef074c52a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010482855\n",
      "./artifacts/unet/unet_epoch_23.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9956a8bcdaeb403f9ccb0f75a8562c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.008350483\n",
      "Epoch 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c255b784583c41e2ab3f6118128f267b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010491047\n",
      "./artifacts/unet/unet_epoch_24.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409d47cfd48d4fa4aa0e7e93d6e47cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.010956488\n",
      "Epoch 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62513559b3364668a67d1cc1308b5d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010481437\n",
      "./artifacts/unet/unet_epoch_25.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0c9fe085a64afc84f5a81c9c90a8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.007915939\n",
      "Epoch 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e43d09cc89640898b27d6e06ad054d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.01049149\n",
      "./artifacts/unet/unet_epoch_26.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6bfbcf408e42289388634c509c909d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.010736061\n",
      "Epoch 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be4842488274249861039bc39bba7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010478895\n",
      "./artifacts/unet/unet_epoch_27.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecca16c0a4d4e9bbdb726d98f9e9352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.01342991\n",
      "Epoch 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acca477a70e49699c24eb4566adccd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010476081\n",
      "./artifacts/unet/unet_epoch_28.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8cd64b2c4144adab0bbe27f6dd6ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.015284052\n",
      "Epoch 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73c3206061349babf062b48ae91d0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010480499\n",
      "./artifacts/unet/unet_epoch_29.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c46135b6be2466783bfb01d610be03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.008934885\n",
      "Epoch 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3399dc21656247728cf8bc83e9c17d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010474398\n",
      "./artifacts/unet/unet_epoch_30.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babb0570a6bc4e3daf450d6eb2ed915f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.00883375\n",
      "Epoch 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befc29442248416792d1bba19104ce5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.01048109\n",
      "./artifacts/unet/unet_epoch_31.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a796d56faee34a5583e26457eed26a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.009674363\n",
      "Epoch 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f698ac06737449ab426f2e76cc14a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.010480321\n",
      "./artifacts/unet/unet_epoch_32.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec6d89e89b449f68e07fd0396abc918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val loss: 0.011033792\n",
      "Epoch 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcaa9079d79430c9f7773562dda03cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/bob/anaconda3/envs/torch37/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2ff72381ab68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtrain_epoch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m#if ii == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m          \u001b[0;31m#   visualize_predictions(X, prediction, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "model = get_unet_model(in_channels=3, num_output_classes=len(classes)+1)\n",
    "model = model.to(device)\n",
    "pretrained_filename = \"unet/unet_epoch_15.pth\"\n",
    "pretrained_filepath = os.path.join(ARTIFACTS_FOLDER, pretrained_filename)\n",
    "model.load_state_dict(torch.load(pretrained_filepath))\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 2e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, 0.5) #optimizer, gamma, last_epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "os.makedirs('./artifacts/unet', exist_ok=True)\n",
    "\n",
    "for epoch in range(16, epochs+1):\n",
    "    ## Train\n",
    "    print(\"Epoch\", epoch)\n",
    "    train_epoch_losses = []\n",
    "    train_bar = tqdm_notebook(trainloader)\n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    for ii, (X, target, sample_ids) in enumerate(train_bar):\n",
    "        X = X.to(device)  # [N, 3, H, W]\n",
    "        target = target.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "        prediction = model(X)  # [N, 2, H, W]\n",
    "        loss = F.cross_entropy(prediction, target, weight=class_weights)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()        \n",
    "        train_epoch_losses.append(loss.detach().cpu().numpy())\n",
    "        #if ii == 0:            \n",
    "         #   visualize_predictions(X, prediction, target)    \n",
    "    train_loss = np.mean(train_epoch_losses)\n",
    "    train_losses.append(train_loss)\n",
    "    print(\"Train Loss:\", train_loss)\n",
    "    checkpoint_filename = \"unet/unet_epoch_{}.pth\".format(epoch)\n",
    "    checkpoint_filepath = os.path.join(ARTIFACTS_FOLDER, checkpoint_filename)\n",
    "    torch.save(model.state_dict(), checkpoint_filepath)\n",
    "    print(checkpoint_filepath)\n",
    "    \n",
    "    ## Val\n",
    "    val_epoch_losses = []\n",
    "    val_bar = tqdm_notebook(valloader)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for ii, (val_X, val_target, batch_sample_tokens) in enumerate(val_bar):\n",
    "            val_X = val_X.to(device)  # [N, 1, H, W]\n",
    "            val_target = val_target.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "            prediction = model(X)  # [N, 2, H, W]\n",
    "            loss = F.cross_entropy(prediction, target, weight=class_weights)\n",
    "            val_epoch_losses.append(loss.detach().cpu().numpy())\n",
    "    val_loss = np.mean(val_epoch_losses)\n",
    "    val_losses.append(val_loss)\n",
    "    print(\"Val loss:\", np.mean(val_loss))\n",
    "x = range(1, epochs+1)\n",
    "plt.plot(x, train_losses, 'bo', linestyle='dashed', linewidth=2, markersize=12)\n",
    "plt.plot(x, val_losses, 'g*', linestyle='dashed', linewidth=2, markersize=12)\n",
    "plt.legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mAP on Val\n",
    "### 计算模型在验证集上的mAP\n",
    "1. 确定预测目标框\n",
    "2. 利用mAP_evaluation.py计算mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读入初始点云数据,后面对语义分割预测结果进行后处理时,需要用到车身的角度等信息\n",
    "level5data = LyftDataset(data_path='.', json_path='/home/bob/data/lyft_data/train_data', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gc\n",
    "from lyft_dataset_sdk.eval.detection.mAP_evaluation import Box3D, recall_precision\n",
    "\n",
    "def val_map(epoch):\n",
    "    ## load model\n",
    "    model = get_unet_model(in_channels=3, num_output_classes=1+len(classes))\n",
    "    model = model.to(device)\n",
    "    checkpoint_filename = \"unet_500/unet_epoch_{}.pth\".format(epoch)\n",
    "    checkpoint_filepath = os.path.join(ARTIFACTS_FOLDER, checkpoint_filename)\n",
    "    model.load_state_dict(torch.load(checkpoint_filepath))\n",
    "    \n",
    "    gc.collect()\n",
    "    progress_bar = tqdm_notebook(valloader)\n",
    "    targets = np.zeros((len(val_target_filepaths), bev_shape[0], bev_shape[1]), dtype=np.uint8)\n",
    "    # We quantize to uint8 here to conserve memory. We're allocating >20GB of memory otherwise.\n",
    "    predictions = np.zeros((len(val_target_filepaths), 1+len(classes), bev_shape[0], \n",
    "                            bev_shape[1]), dtype=np.uint8)\n",
    "    sample_tokens = []\n",
    "    \n",
    "    ## predict\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for ii, (X, target, batch_sample_tokens) in enumerate(progress_bar):\n",
    "            offset = ii*batch_size\n",
    "            targets[offset:offset+batch_size] = target.numpy()\n",
    "            sample_tokens.extend(batch_sample_tokens)\n",
    "            X = X.to(device)  # [N, 1, H, W]\n",
    "            target = target.to(device)  # [N, H, W] with class indices (0, 1)\n",
    "            prediction = model(X)  # [N, 2, H, W]\n",
    "            prediction = F.softmax(prediction, dim=1)\n",
    "            prediction_cpu = prediction.cpu().numpy()\n",
    "            predictions[offset:offset+batch_size] = np.round(prediction_cpu*255).astype(np.uint8)\n",
    "    predictions_non_class0 = 255 - predictions[:,0]   \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "    predictions_opened = np.zeros((predictions_non_class0.shape), dtype=np.uint8)\n",
    "    background_threshold = 255//2\n",
    "    for i, p in enumerate(tqdm(predictions_non_class0)):\n",
    "        thresholded_p = (p > background_threshold).astype(np.uint8)\n",
    "        predictions_opened[i] = cv2.morphologyEx(thresholded_p, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    ## 2d detection\n",
    "    detection_boxes = []\n",
    "    detection_scores = []\n",
    "    detection_classes = []\n",
    "\n",
    "    for i in tqdm_notebook(range(len(predictions))):\n",
    "        prediction_opened = predictions_opened[i]\n",
    "        probability_non_class0 = predictions_non_class0[i]\n",
    "        class_probability = predictions[i]\n",
    "        sample_boxes = []\n",
    "        sample_detection_scores = []\n",
    "        sample_detection_classes = []\n",
    "        contours, hierarchy = cv2.findContours(prediction_opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)     \n",
    "        for cnt in contours:\n",
    "            rect = cv2.minAreaRect(cnt)\n",
    "            box = cv2.boxPoints(rect)        \n",
    "            # Let's take the center pixel value as the confidence value\n",
    "            box_center_index = np.int0(np.mean(box, axis=0))        \n",
    "            for class_index in range(len(classes)):\n",
    "                box_center_value = class_probability[class_index+1, box_center_index[1], box_center_index[0]]            \n",
    "                # Let's remove candidates with very low probability\n",
    "                if box_center_value < 0.01:\n",
    "                    continue            \n",
    "                box_center_class = classes[class_index]\n",
    "                box_detection_score = box_center_value\n",
    "                sample_detection_classes.append(box_center_class)\n",
    "                sample_detection_scores.append(box_detection_score)\n",
    "                sample_boxes.append(box)            \n",
    "        detection_boxes.append(np.array(sample_boxes))\n",
    "        detection_scores.append(sample_detection_scores)\n",
    "        detection_classes.append(sample_detection_classes)\n",
    "    \n",
    "    ## 3d detection\n",
    "    pred_box3ds = []\n",
    "    for (sample_token, sample_boxes, sample_detection_scores, sample_detection_class) in tqdm_notebook(\n",
    "            zip(sample_tokens, detection_boxes, detection_scores, \n",
    "            detection_classes), total=len(sample_tokens)):\n",
    "        sample_boxes = sample_boxes.reshape(-1, 2) # (N, 4, 2) -> (N*4, 2)\n",
    "        sample_boxes = sample_boxes.transpose(1,0) # (N*4, 2) -> (2, N*4)\n",
    "        # Add Z dimension\n",
    "        sample_boxes = np.vstack((sample_boxes, np.zeros(sample_boxes.shape[1]),)) # (2, N*4) -> (3, N*4)\n",
    "        sample = level5data.get(\"sample\", sample_token)\n",
    "        sample_lidar_token = sample[\"data\"][\"LIDAR_TOP\"]\n",
    "        lidar_data = level5data.get(\"sample_data\", sample_lidar_token)\n",
    "        lidar_filepath = level5data.get_sample_data_path(sample_lidar_token)\n",
    "        ego_pose = level5data.get(\"ego_pose\", lidar_data[\"ego_pose_token\"])\n",
    "        ego_translation = np.array(ego_pose['translation'])\n",
    "        global_from_car = transform_matrix(ego_pose['translation'],\n",
    "                                       Quaternion(ego_pose['rotation']), inverse=False)\n",
    "        car_from_voxel = np.linalg.inv(create_transformation_matrix_to_voxel_space(\n",
    "                                        bev_shape, voxel_size, (0, 0, z_offset)))\n",
    "        global_from_voxel = np.dot(global_from_car, car_from_voxel)\n",
    "        sample_boxes = transform_points(sample_boxes, global_from_voxel)\n",
    "        sample_boxes[2,:] = ego_pose[\"translation\"][2]\n",
    "        # (3, N*4) -> (N, 4, 3)\n",
    "        sample_boxes = sample_boxes.transpose(1,0).reshape(-1, 4, 3)\n",
    "        # We don't know the height of our boxes, let's assume every object is the same height.\n",
    "        box_height = 1.75\n",
    "        sample_boxes_centers = sample_boxes.mean(axis=1)\n",
    "        sample_boxes_centers[:,2] += box_height/2    \n",
    "        sample_lengths = np.linalg.norm(sample_boxes[:,0,:] - sample_boxes[:,1,:], axis=1) * 1/box_scale\n",
    "        sample_widths = np.linalg.norm(sample_boxes[:,1,:] - sample_boxes[:,2,:], axis=1) * 1/box_scale    \n",
    "        sample_boxes_dimensions = np.zeros_like(sample_boxes_centers) \n",
    "        sample_boxes_dimensions[:,0] = sample_widths\n",
    "        sample_boxes_dimensions[:,1] = sample_lengths\n",
    "        sample_boxes_dimensions[:,2] = box_height\n",
    "        for i in range(len(sample_boxes)):\n",
    "            translation = sample_boxes_centers[i]\n",
    "            size = sample_boxes_dimensions[i]\n",
    "            class_name = sample_detection_class[i]\n",
    "            ego_distance = float(np.linalg.norm(ego_translation - translation))          \n",
    "            # Determine the rotation of the box\n",
    "            v = (sample_boxes[i,0] - sample_boxes[i,1])\n",
    "            v /= np.linalg.norm(v)\n",
    "            r = R.from_dcm([ # initialization from direction cosine matrices\n",
    "                [v[0], -v[1], 0],\n",
    "                [v[1],  v[0], 0],\n",
    "                [   0,     0, 1],\n",
    "            ])\n",
    "            quat = r.as_quat() # as quaternions\n",
    "            # XYZW -> WXYZ order of elements\n",
    "            quat = quat[[3,0,1,2]]        \n",
    "            detection_score = float(sample_detection_scores[i])        \n",
    "            box3d = Box3D(\n",
    "                sample_token=sample_token,\n",
    "                translation=list(translation),\n",
    "                size=list(size),\n",
    "                rotation=list(quat),\n",
    "                name=class_name,\n",
    "                score=detection_score\n",
    "            )\n",
    "            pred_box3ds.append(box3d)\n",
    "    \n",
    "    ## mAP calc\n",
    "    pred = [b.serialize() for b in pred_box3ds]\n",
    "    with open(os.path.join(ARTIFACTS_FOLDER, \"json/unet500/pred_{}.json\".format(epoch)), \"w\") as f:\n",
    "        json.dump(pred, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc7bcfb993842a49af138259bfffe85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob/anaconda3/envs/torch37/lib/python3.7/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5040/5040 [00:01<00:00, 4235.28it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba5e6ebeb9743baa397537c1640de6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5040), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cef1524241490aa95b10d5658afb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5040), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd2285b61b74d3c96b8671f308fc784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=630), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5040/5040 [00:01<00:00, 4025.14it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a6429a899e4582b1078dbe43236883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5040), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c73afeb7a24ab3985ecc2dcd389f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5040), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_map(epoch=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class_names =  ['animal', 'bicycle', 'bus', 'car', 'motorcycle', 'other_vehicle', 'pedestrian', 'truck']\n",
      "Average per class mean average precision =  0.1050620193022741\n",
      "('animal', 0.0)\n",
      "('bicycle', 0.03192542878666849)\n",
      "('bus', 0.051367276695549226)\n",
      "('car', 0.485934698561018)\n",
      "('motorcycle', 0.012984378170014202)\n",
      "('other_vehicle', 0.24332543008689356)\n",
      "('pedestrian', 0.007177650093509974)\n",
      "('truck', 0.007781292024539437)\n"
     ]
    }
   ],
   "source": [
    "!python ./eval/mAP_evaluation.py --pred_file './artifacts/json/unet500/pred_12.json' --gt/home/bob/code/lyft/eval_file \"./artifacts/gt.json\" --iou_threshold 0.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
